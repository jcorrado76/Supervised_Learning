{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Architecture\n",
    "In the LeNet-5 convolutional architecture, used on the MNIST input images, we have 32x32 images as our data input. \n",
    "\n",
    "For this architecture, the layers are:\n",
    "1. Convolution\n",
    "2. Max Pooling\n",
    "3. Convolution \n",
    "4. Max Pooling\n",
    "5. Fully connected\n",
    "6. Full connected\n",
    "7. Output layer\n",
    "\n",
    "Define the basic constants for the LeNet-5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import gzip\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_URL = 'http://yann.lecun.com/exdb/mnist/'\n",
    "WORK_DIRECTORY = 'data/mnist_data'\n",
    "NUM_CHANNELS = 1\n",
    "PIXEL_DEPTH = 255\n",
    "IMAGE_SIZE = 28\n",
    "NUM_LABELS = 10\n",
    "VALIDATION_SIZE = 5000  # Size of the validation set.\n",
    "SEED = 66478  # Set to None for random seed.\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 10\n",
    "EVAL_BATCH_SIZE = 64\n",
    "EVAL_FREQUENCY = 100  # Number of steps between evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def download(filename):\n",
    "    \"\"\"\n",
    "    Download the data from Yann's website, unless it's already here.\n",
    "    \"\"\"\n",
    "    # if there is no local directory named 'data'\n",
    "    if not os.path.exists(WORK_DIRECTORY):\n",
    "        # create it\n",
    "        os.makedirs(WORK_DIRECTORY)\n",
    "    # create target filename\n",
    "    filepath = os.path.join(WORK_DIRECTORY, filename)\n",
    "    # if the file is not already there in the data directory\n",
    "    if not os.path.exists(filepath):\n",
    "        # use urllib to download it\n",
    "        filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename,filepath)\n",
    "    # get the size of the downloaded file\n",
    "    size = os.stat(filepath).st_size\n",
    "    # print out the file name and its size\n",
    "    print('Successfully downloaded', filename, size, 'bytes.')\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def extract_data(filename, num_images):\n",
    "    \"\"\"\n",
    "    Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
    "    \"\"\"\n",
    "    # print the file currently extracting\n",
    "    print('Extracting', filename)\n",
    "    # open the file\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        # discard the header\n",
    "        bytestream.read(16)\n",
    "        # read in the data\n",
    "        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)\n",
    "        data = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)\n",
    "    # The original data consists of pixels ranging from 0-255.\n",
    "    # Center the data to have mean zero, and unit range.\n",
    "    data = (data - (255/2.0))/255 \n",
    "    data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE,\n",
    "                        NUM_CHANNELS)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"\n",
    "    Extract the labels into a vector of int64 label IDs.\n",
    "    \"\"\"\n",
    "    # show which file is currently being extracted\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        # Discard header.\n",
    "        bytestream.read(8)\n",
    "        # Read bytes for labels.\n",
    "        buf = bytestream.read(num_images)\n",
    "        labels = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.int64)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def error_rate(predictions, labels):\n",
    "    \"\"\"\n",
    "    Return the error rate based on dense predictions and sparse labels.\n",
    "    \"\"\"\n",
    "    return 100.0 - (100.0 * numpy.sum(numpy.argmax(predictions, 1) == labels) / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def model( data, train=False ):\n",
    "    \"\"\"\n",
    "    The definition of our CNN model\n",
    "    \"\"\"\n",
    "    # we use SAME padding so that the output feature map has the same size as the input\n",
    "    # stride is a 4D array whose shape matches the data layout of [image_index, y, x, depth]\n",
    "    conv1 = tf.nn.conv2d( data, conv1_weights, strides=[1,1,1,1], padding=\"SAME\" )\n",
    "    # we create the bias term and wrap the logit in rectified linear non-linearity\n",
    "    relu1 = tf.nn.relu( tf.nn.bias_add( conv1, conv1_biases ) )\n",
    "    # max pooling. we use a pooling window of 2 and a stride of 2.\n",
    "    # ksize follows the layout of the data\n",
    "    pool1 = tf.nn.max_pool( relu1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\" )\n",
    "    conv2 = tf.nn.conv2d( pool1, conv2_weights, strides=[1,1,1,1], padding=\"SAME\" )\n",
    "    relu2 = tf.nn.relu( tf.nn.bias_add( conv2, conv2_biases ) )\n",
    "    pool2 = tf.nn.max_pool( relu2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\" )\n",
    "    pool_shape = pool2.get_shape().as_list()\n",
    "    # reshape the input data cuboid into a 2D matrix to feed it to the fully connected layers\n",
    "    reshape = tf.reshape( pool2, [pool_shape[0], pool_shape[1] * pool_shape[2] * pool_shape[3]] )\n",
    "    # note that the \"+\" broadcasts the biases appropriately\n",
    "    hidden = tf.nn.relu( tf.matmul(reshape, fc1_weights) + fc1_biases )\n",
    "    # if we're training\n",
    "    if train:\n",
    "        # add a 50% dropout. dropout scales activations such that no rescaling is needed at evaluation time\n",
    "        hidden = tf.nn.dropout( hidden, 0.5, seed=SEED )\n",
    "    return tf.matmul( hidden, fc2_weights ) + fc2_biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/mnist_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/mnist_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/mnist_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Get the data.\n",
    "train_data_filename = download('train-images-idx3-ubyte.gz')\n",
    "train_labels_filename = download('train-labels-idx1-ubyte.gz')\n",
    "test_data_filename = download('t10k-images-idx3-ubyte.gz')\n",
    "test_labels_filename = download('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "# Extract it into numpy arrays.\n",
    "train_data = extract_data(train_data_filename, 60000)\n",
    "train_labels = extract_labels(train_labels_filename, 60000)\n",
    "test_data = extract_data(test_data_filename, 10000)\n",
    "test_labels = extract_labels(test_labels_filename, 10000)\n",
    "\n",
    "# Generate a validation set.\n",
    "validation_data = train_data[:VALIDATION_SIZE, ...]\n",
    "validation_labels = train_labels[:VALIDATION_SIZE]\n",
    "train_data = train_data[VALIDATION_SIZE:, ...]\n",
    "train_labels = train_labels[VALIDATION_SIZE:]\n",
    "\n",
    "num_epochs = NUM_EPOCHS\n",
    "train_size = train_labels.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholders to feed data into CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where training samples and labels are fed to the graph.\n",
    "# These placeholder nodes will be fed a batch of training data at each\n",
    "# training step using the {feed_dict} argument to the Run() call below.\n",
    "train_data_node = tf.placeholder(tf.float32,shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "train_labels_node = tf.placeholder(tf.int64, shape=(BATCH_SIZE,))\n",
    "eval_data = tf.placeholder(tf.float32,shape=(EVAL_BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the learnable weights for the convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a 5x5 filter of depth 32\n",
    "conv1_weights = tf.Variable(tf.truncated_normal([5, 5, NUM_CHANNELS, 32],\n",
    "                                                stddev=0.1,\n",
    "                                                seed=SEED, dtype=tf.float32))\n",
    "conv1_biases = tf.Variable(tf.zeros([32], dtype=tf.float32))\n",
    "conv2_weights = tf.Variable(tf.truncated_normal([5, 5, 32, 64], stddev=0.1, seed=SEED, dtype=tf.float32))\n",
    "conv2_biases = tf.Variable(tf.constant(0.1, shape=[64], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the learnable weights for the fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1_weights = tf.Variable(tf.truncated_normal([IMAGE_SIZE // 4 * IMAGE_SIZE // 4 * 64, 512],\\\n",
    "                                             stddev=0.1,seed=SEED, dtype=tf.float32))\n",
    "fc1_biases = tf.Variable(tf.constant(0.1, shape=[512], dtype=tf.float32))\n",
    "fc2_weights = tf.Variable(tf.truncated_normal([512, NUM_LABELS], stddev=0.1, seed=SEED, dtype=tf.float32))\n",
    "fc2_biases = tf.Variable(tf.constant(0.1, shape=[NUM_LABELS], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0801 16:50:08.032005 140709209909056 deprecation.py:506] From <ipython-input-7-1bd9a9572416>:24: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "logits = model(train_data_node, True)\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    labels=train_labels_node, logits=logits))\n",
    "\n",
    "# L2 regularization for the fully connected parameters.\n",
    "regularizers = (tf.nn.l2_loss(fc1_weights)\n",
    "                + tf.nn.l2_loss(fc1_biases)\n",
    "                + tf.nn.l2_loss(fc2_weights)\n",
    "                + tf.nn.l2_loss(fc2_biases))\n",
    "# Add the regularization term to the loss.\n",
    "loss += 5e-4 * regularizers\n",
    "\n",
    "# Optimizer: set up a variable that's incremented once per batch and\n",
    "# controls the learning rate decay.\n",
    "batch = tf.Variable(0, dtype=tf.float32)\n",
    "# Decay once per epoch, using an exponential schedule starting at 0.01.\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    0.01,                # Base learning rate.\n",
    "    batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "    train_size,          # Decay step.\n",
    "    0.95,                # Decay rate.\n",
    "    staircase=True)\n",
    "# Use simple momentum for the optimization.\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate,\n",
    "                                       0.9).minimize(loss,\n",
    "                                                     global_step=batch)\n",
    "\n",
    "# Predictions for the current training minibatch.\n",
    "train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Predictions for the test and validation, which we'll compute less\n",
    "# often.\n",
    "eval_prediction = tf.nn.softmax(model(eval_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small utility function to evaluate a dataset by feeding batches of\n",
    "# data to {eval_data} and pulling the results from {eval_predictions}.\n",
    "# Saves memory and enables this to run on smaller GPUs.\n",
    "def eval_in_batches(data, sess):\n",
    "    \"\"\"Get predictions for a dataset by running it in small batches.\"\"\"\n",
    "    size = data.shape[0]\n",
    "    if size < EVAL_BATCH_SIZE:\n",
    "        raise ValueError(\"batch size for evals larger than dataset: %d\"\n",
    "                     % size)\n",
    "    predictions = numpy.ndarray(shape=(size, NUM_LABELS),\n",
    "                              dtype=numpy.float32)\n",
    "    for begin in xrange(0, size, EVAL_BATCH_SIZE):\n",
    "        end = begin + EVAL_BATCH_SIZE\n",
    "        if end <= size:\n",
    "            predictions[begin:end, :] = sess.run(\n",
    "            eval_prediction,\n",
    "            feed_dict={eval_data: data[begin:end, ...]})\n",
    "    else:\n",
    "        batch_predictions = sess.run(\n",
    "        eval_prediction,\n",
    "        feed_dict={eval_data: data[-EVAL_BATCH_SIZE:, ...]})\n",
    "        predictions[begin:, :] = batch_predictions[begin - size:, :]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 (epoch 0.00), 4.0 ms\n",
      "Minibatch loss: 8.334, learning rate: 0.010000\n",
      "Minibatch error: 85.9%\n",
      "Validation error: 84.6%\n",
      "Step 100 (epoch 0.12), 41.5 ms\n",
      "Minibatch loss: 3.266, learning rate: 0.010000\n",
      "Minibatch error: 7.8%\n",
      "Validation error: 8.6%\n",
      "Step 200 (epoch 0.23), 40.5 ms\n",
      "Minibatch loss: 3.380, learning rate: 0.010000\n",
      "Minibatch error: 10.9%\n",
      "Validation error: 4.4%\n",
      "Step 300 (epoch 0.35), 40.8 ms\n",
      "Minibatch loss: 3.170, learning rate: 0.010000\n",
      "Minibatch error: 3.1%\n",
      "Validation error: 3.0%\n",
      "Step 400 (epoch 0.47), 40.7 ms\n",
      "Minibatch loss: 3.185, learning rate: 0.010000\n",
      "Minibatch error: 7.8%\n",
      "Validation error: 2.7%\n",
      "Step 500 (epoch 0.58), 41.0 ms\n",
      "Minibatch loss: 3.170, learning rate: 0.010000\n",
      "Minibatch error: 3.1%\n",
      "Validation error: 2.6%\n",
      "Step 600 (epoch 0.70), 40.3 ms\n",
      "Minibatch loss: 3.143, learning rate: 0.010000\n",
      "Minibatch error: 3.1%\n",
      "Validation error: 2.1%\n",
      "Step 700 (epoch 0.81), 40.8 ms\n",
      "Minibatch loss: 2.978, learning rate: 0.010000\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 2.2%\n",
      "Step 800 (epoch 0.93), 40.9 ms\n",
      "Minibatch loss: 3.035, learning rate: 0.010000\n",
      "Minibatch error: 4.7%\n",
      "Validation error: 2.0%\n",
      "Step 900 (epoch 1.05), 41.4 ms\n",
      "Minibatch loss: 2.934, learning rate: 0.009500\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.8%\n",
      "Step 1000 (epoch 1.16), 40.9 ms\n",
      "Minibatch loss: 2.866, learning rate: 0.009500\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.9%\n",
      "Step 1100 (epoch 1.28), 41.0 ms\n",
      "Minibatch loss: 2.821, learning rate: 0.009500\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.5%\n",
      "Step 1200 (epoch 1.40), 40.6 ms\n",
      "Minibatch loss: 2.976, learning rate: 0.009500\n",
      "Minibatch error: 3.1%\n",
      "Validation error: 1.4%\n",
      "Step 1300 (epoch 1.51), 40.8 ms\n",
      "Minibatch loss: 2.808, learning rate: 0.009500\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.7%\n",
      "Step 1400 (epoch 1.63), 40.9 ms\n",
      "Minibatch loss: 2.827, learning rate: 0.009500\n",
      "Minibatch error: 3.1%\n",
      "Validation error: 1.6%\n",
      "Step 1500 (epoch 1.75), 41.0 ms\n",
      "Minibatch loss: 2.846, learning rate: 0.009500\n",
      "Minibatch error: 3.1%\n",
      "Validation error: 1.4%\n",
      "Step 1600 (epoch 1.86), 41.3 ms\n",
      "Minibatch loss: 2.740, learning rate: 0.009500\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.4%\n",
      "Step 1700 (epoch 1.98), 40.7 ms\n",
      "Minibatch loss: 2.652, learning rate: 0.009500\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 1.5%\n",
      "Step 1800 (epoch 2.09), 41.4 ms\n",
      "Minibatch loss: 2.640, learning rate: 0.009025\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 1.2%\n",
      "Step 1900 (epoch 2.21), 40.8 ms\n",
      "Minibatch loss: 2.626, learning rate: 0.009025\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 1.2%\n",
      "Step 2000 (epoch 2.33), 40.6 ms\n",
      "Minibatch loss: 2.601, learning rate: 0.009025\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.2%\n",
      "Step 2100 (epoch 2.44), 40.2 ms\n",
      "Minibatch loss: 2.591, learning rate: 0.009025\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.1%\n",
      "Step 2200 (epoch 2.56), 41.0 ms\n",
      "Minibatch loss: 2.586, learning rate: 0.009025\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.2%\n",
      "Step 2300 (epoch 2.68), 41.6 ms\n",
      "Minibatch loss: 2.608, learning rate: 0.009025\n",
      "Minibatch error: 3.1%\n",
      "Validation error: 1.2%\n",
      "Step 2400 (epoch 2.79), 41.9 ms\n",
      "Minibatch loss: 2.500, learning rate: 0.009025\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 1.2%\n",
      "Step 2500 (epoch 2.91), 40.9 ms\n",
      "Minibatch loss: 2.477, learning rate: 0.009025\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 1.2%\n",
      "Step 2600 (epoch 3.03), 41.5 ms\n",
      "Minibatch loss: 2.472, learning rate: 0.008574\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.2%\n",
      "Step 2700 (epoch 3.14), 40.5 ms\n",
      "Minibatch loss: 2.487, learning rate: 0.008574\n",
      "Minibatch error: 3.1%\n",
      "Validation error: 1.2%\n",
      "Step 2800 (epoch 3.26), 41.5 ms\n",
      "Minibatch loss: 2.449, learning rate: 0.008574\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.2%\n",
      "Step 2900 (epoch 3.37), 40.7 ms\n",
      "Minibatch loss: 2.500, learning rate: 0.008574\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.1%\n",
      "Step 3000 (epoch 3.49), 41.2 ms\n",
      "Minibatch loss: 2.413, learning rate: 0.008574\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.0%\n",
      "Step 3100 (epoch 3.61), 41.1 ms\n",
      "Minibatch loss: 2.372, learning rate: 0.008574\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.0%\n",
      "Step 3200 (epoch 3.72), 40.8 ms\n",
      "Minibatch loss: 2.374, learning rate: 0.008574\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.2%\n",
      "Step 3300 (epoch 3.84), 40.9 ms\n",
      "Minibatch loss: 2.364, learning rate: 0.008574\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.0%\n",
      "Step 3400 (epoch 3.96), 41.3 ms\n",
      "Minibatch loss: 2.289, learning rate: 0.008574\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 1.1%\n",
      "Step 3500 (epoch 4.07), 42.1 ms\n",
      "Minibatch loss: 2.284, learning rate: 0.008145\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 1.0%\n",
      "Step 3600 (epoch 4.19), 42.9 ms\n",
      "Minibatch loss: 2.248, learning rate: 0.008145\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 1.0%\n",
      "Step 3700 (epoch 4.31), 41.8 ms\n",
      "Minibatch loss: 2.229, learning rate: 0.008145\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 1.0%\n",
      "Step 3800 (epoch 4.42), 41.9 ms\n",
      "Minibatch loss: 2.220, learning rate: 0.008145\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.9%\n",
      "Step 3900 (epoch 4.54), 43.2 ms\n",
      "Minibatch loss: 2.272, learning rate: 0.008145\n",
      "Minibatch error: 3.1%\n",
      "Validation error: 1.0%\n",
      "Step 4000 (epoch 4.65), 41.4 ms\n",
      "Minibatch loss: 2.282, learning rate: 0.008145\n",
      "Minibatch error: 4.7%\n",
      "Validation error: 1.0%\n",
      "Step 4100 (epoch 4.77), 41.0 ms\n",
      "Minibatch loss: 2.192, learning rate: 0.008145\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.0%\n",
      "Step 4200 (epoch 4.89), 41.5 ms\n",
      "Minibatch loss: 2.166, learning rate: 0.008145\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.1%\n",
      "Step 4300 (epoch 5.00), 41.5 ms\n",
      "Minibatch loss: 2.267, learning rate: 0.007738\n",
      "Minibatch error: 6.2%\n",
      "Validation error: 1.0%\n",
      "Step 4400 (epoch 5.12), 41.6 ms\n",
      "Minibatch loss: 2.146, learning rate: 0.007738\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.0%\n",
      "Step 4500 (epoch 5.24), 41.7 ms\n",
      "Minibatch loss: 2.153, learning rate: 0.007738\n",
      "Minibatch error: 3.1%\n",
      "Validation error: 1.0%\n",
      "Step 4600 (epoch 5.35), 41.1 ms\n",
      "Minibatch loss: 2.092, learning rate: 0.007738\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.0%\n",
      "Step 4700 (epoch 5.47), 41.3 ms\n",
      "Minibatch loss: 2.130, learning rate: 0.007738\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 0.9%\n",
      "Step 4800 (epoch 5.59), 41.8 ms\n",
      "Minibatch loss: 2.076, learning rate: 0.007738\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 0.9%\n",
      "Step 4900 (epoch 5.70), 41.2 ms\n",
      "Minibatch loss: 2.054, learning rate: 0.007738\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.0%\n",
      "Step 5000 (epoch 5.82), 41.0 ms\n",
      "Minibatch loss: 2.139, learning rate: 0.007738\n",
      "Minibatch error: 4.7%\n",
      "Validation error: 0.8%\n",
      "Step 5100 (epoch 5.93), 40.9 ms\n",
      "Minibatch loss: 2.004, learning rate: 0.007738\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 1.1%\n",
      "Step 5200 (epoch 6.05), 41.5 ms\n",
      "Minibatch loss: 2.115, learning rate: 0.007351\n",
      "Minibatch error: 6.2%\n",
      "Validation error: 1.0%\n",
      "Step 5300 (epoch 6.17), 41.1 ms\n",
      "Minibatch loss: 1.970, learning rate: 0.007351\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 1.0%\n",
      "Step 5400 (epoch 6.28), 41.1 ms\n",
      "Minibatch loss: 1.954, learning rate: 0.007351\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 1.0%\n",
      "Step 5500 (epoch 6.40), 41.7 ms\n",
      "Minibatch loss: 1.971, learning rate: 0.007351\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.0%\n",
      "Step 5600 (epoch 6.52), 43.6 ms\n",
      "Minibatch loss: 1.935, learning rate: 0.007351\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.9%\n",
      "Step 5700 (epoch 6.63), 40.8 ms\n",
      "Minibatch loss: 1.912, learning rate: 0.007351\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.9%\n",
      "Step 5800 (epoch 6.75), 41.5 ms\n",
      "Minibatch loss: 1.897, learning rate: 0.007351\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 1.0%\n",
      "Step 5900 (epoch 6.87), 42.0 ms\n",
      "Minibatch loss: 1.897, learning rate: 0.007351\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.9%\n",
      "Step 6000 (epoch 6.98), 41.7 ms\n",
      "Minibatch loss: 1.900, learning rate: 0.007351\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.9%\n",
      "Step 6100 (epoch 7.10), 42.3 ms\n",
      "Minibatch loss: 1.867, learning rate: 0.006983\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 1.0%\n",
      "Step 6200 (epoch 7.21), 40.8 ms\n",
      "Minibatch loss: 1.844, learning rate: 0.006983\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.9%\n",
      "Step 6300 (epoch 7.33), 41.2 ms\n",
      "Minibatch loss: 1.835, learning rate: 0.006983\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.9%\n",
      "Step 6400 (epoch 7.45), 40.5 ms\n",
      "Minibatch loss: 1.826, learning rate: 0.006983\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.9%\n",
      "Step 6500 (epoch 7.56), 40.9 ms\n",
      "Minibatch loss: 1.807, learning rate: 0.006983\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.9%\n",
      "Step 6600 (epoch 7.68), 40.3 ms\n",
      "Minibatch loss: 1.810, learning rate: 0.006983\n",
      "Minibatch error: 1.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error: 0.9%\n",
      "Step 6700 (epoch 7.80), 40.6 ms\n",
      "Minibatch loss: 1.781, learning rate: 0.006983\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.9%\n",
      "Step 6800 (epoch 7.91), 43.0 ms\n",
      "Minibatch loss: 1.779, learning rate: 0.006983\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.9%\n",
      "Step 6900 (epoch 8.03), 37.4 ms\n",
      "Minibatch loss: 1.759, learning rate: 0.006634\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.9%\n",
      "Step 7000 (epoch 8.15), 35.4 ms\n",
      "Minibatch loss: 1.748, learning rate: 0.006634\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 1.0%\n",
      "Step 7100 (epoch 8.26), 35.4 ms\n",
      "Minibatch loss: 1.734, learning rate: 0.006634\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.9%\n",
      "Step 7200 (epoch 8.38), 35.3 ms\n",
      "Minibatch loss: 1.731, learning rate: 0.006634\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.9%\n",
      "Step 7300 (epoch 8.49), 34.9 ms\n",
      "Minibatch loss: 1.742, learning rate: 0.006634\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 0.9%\n",
      "Step 7400 (epoch 8.61), 35.2 ms\n",
      "Minibatch loss: 1.700, learning rate: 0.006634\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.8%\n",
      "Step 7500 (epoch 8.73), 34.8 ms\n",
      "Minibatch loss: 1.700, learning rate: 0.006634\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.9%\n",
      "Step 7600 (epoch 8.84), 34.9 ms\n",
      "Minibatch loss: 1.761, learning rate: 0.006634\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 0.9%\n",
      "Step 7700 (epoch 8.96), 35.0 ms\n",
      "Minibatch loss: 1.666, learning rate: 0.006634\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 1.0%\n",
      "Step 7800 (epoch 9.08), 34.8 ms\n",
      "Minibatch loss: 1.660, learning rate: 0.006302\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.8%\n",
      "Step 7900 (epoch 9.19), 34.9 ms\n",
      "Minibatch loss: 1.645, learning rate: 0.006302\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.9%\n",
      "Step 8000 (epoch 9.31), 35.3 ms\n",
      "Minibatch loss: 1.645, learning rate: 0.006302\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.9%\n",
      "Step 8100 (epoch 9.43), 34.8 ms\n",
      "Minibatch loss: 1.630, learning rate: 0.006302\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.8%\n",
      "Step 8200 (epoch 9.54), 35.2 ms\n",
      "Minibatch loss: 1.625, learning rate: 0.006302\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.9%\n",
      "Step 8300 (epoch 9.66), 34.8 ms\n",
      "Minibatch loss: 1.630, learning rate: 0.006302\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 0.9%\n",
      "Step 8400 (epoch 9.77), 34.9 ms\n",
      "Minibatch loss: 1.599, learning rate: 0.006302\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.9%\n",
      "Step 8500 (epoch 9.89), 35.2 ms\n",
      "Minibatch loss: 1.620, learning rate: 0.006302\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 0.9%\n",
      "Test error: 0.7%\n"
     ]
    }
   ],
   "source": [
    "# Create a local session to run the training.\n",
    "start_time = time.time()\n",
    "with tf.Session() as sess:\n",
    "    # Run all the initializers to prepare the trainable parameters.\n",
    "    tf.global_variables_initializer().run()\n",
    "    # Loop through training steps.\n",
    "    for step in xrange(int(num_epochs * train_size) // BATCH_SIZE):\n",
    "        # Compute the offset of the current minibatch in the data.\n",
    "        # Note that we could use better randomization across epochs.\n",
    "        offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n",
    "        batch_data = train_data[offset:(offset + BATCH_SIZE), ...]\n",
    "        batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "        # This dictionary maps the batch data (as a numpy array) to the\n",
    "        # node in the graph it should be fed to.\n",
    "        feed_dict = {train_data_node: batch_data,\n",
    "                     train_labels_node: batch_labels}\n",
    "        # Run the optimizer to update weights.\n",
    "        sess.run(optimizer, feed_dict=feed_dict)\n",
    "        # print some extra information once reach the evaluation frequency\n",
    "        if step % EVAL_FREQUENCY == 0:\n",
    "            # fetch some extra nodes' data\n",
    "            l, lr, predictions = sess.run([loss, learning_rate,\n",
    "                                         train_prediction],\n",
    "                                        feed_dict=feed_dict)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            start_time = time.time()\n",
    "            print('Step %d (epoch %.2f), %.1f ms' %\n",
    "                (step, float(step) * BATCH_SIZE / train_size,\n",
    "                 1000 * elapsed_time / EVAL_FREQUENCY))\n",
    "            print('Minibatch loss: %.3f, learning rate: %.6f' % (l, lr))\n",
    "            print('Minibatch error: %.1f%%'\n",
    "                % error_rate(predictions, batch_labels))\n",
    "            print('Validation error: %.1f%%' % error_rate(\n",
    "              eval_in_batches(validation_data, sess), validation_labels))\n",
    "            sys.stdout.flush()\n",
    "    # Finally print the result!\n",
    "    test_error = error_rate(eval_in_batches(test_data, sess),\n",
    "                          test_labels)\n",
    "    print('Test error: %.1f%%' % test_error)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
